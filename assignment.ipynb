{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T01:55:40.151200Z",
     "start_time": "2024-04-29T01:55:38.923148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import the data set\n",
    "data = pd.read_csv('car_prices.csv')"
   ],
   "id": "c84198a6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Get the general information of this data set\n",
    "data.info()"
   ],
   "id": "bcbf742c192c1c85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Get 100 rows in random\n",
    "data.sample(100)"
   ],
   "id": "dd8c7220e7bfc832",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "816a1e32648ba57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T01:56:25.884247Z",
     "start_time": "2024-04-29T01:56:25.535092Z"
    }
   },
   "source": [
    "#Creat a list to store the invalid values, so we can replace them as NAN and remove them later.\n",
    "rubbish_values = []\n",
    "#Find the unique value column by column\n",
    "for column in data.columns:  \n",
    "    unique_values = data[column].unique()\n",
    "    print(column, end=\":\")\n",
    "    #Iterate through all the unique values to probe for possible invalid non-null values\n",
    "    for unique_value in unique_values:\n",
    "        #If the length of unique_value is equal to 1, then I recognize it as invalid values.\n",
    "        if len(str(unique_value)) == 1:\n",
    "            #Print invalid values and add them into the list\n",
    "            rubbish_values.append(str(unique_value))  \n",
    "            print(unique_value, end=\", \")\n",
    "    #After one column finished iterating, change to next line to prepare for the iteration of next column.        \n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year:\n",
      "make:\n",
      "model:M, 7, 3, 6, 1, e, \n",
      "trim:+, L, S, 2, 4, C, !, X, 3, i, s, x, 1, R, l, 5, V, I, G, \n",
      "body:\n",
      "transmission:\n",
      "vin:\n",
      "state:\n",
      "condition:\n",
      "odometer:\n",
      "color:—, \n",
      "interior:—, \n",
      "seller:\n",
      "mmr:\n",
      "sellingprice:\n",
      "saledate:\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T01:56:34.860286Z",
     "start_time": "2024-04-29T01:56:30.829137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for rubbish_value in rubbish_values:  #Replace the exist invalid values by particular value NAN\n",
    "    data.replace(rubbish_value, np.nan, inplace=True)\n",
    "data.dropna(inplace=True)  #Remove all rows with at least one column contain NAN as its value."
   ],
   "id": "3ca98315f4427f30",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Use isna() to judge whether the value is NaN or not,\n",
    "# if the value is NaN,it will return True, otherwise it will return False\n",
    "# and then use sum() to calculate the total number of True to know how many NaN values.\n",
    "data.isnull().sum()"
   ],
   "id": "293ee28a0935cc51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Show the general information of cleaned data set\n",
    "data.info()"
   ],
   "id": "951c8ebebe696c9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#get first 100 rows to know the general information of this data set\n",
    "data.head(100)"
   ],
   "id": "22c55d8d774c61a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Get the last 100 rows\n",
    "data.tail(100)"
   ],
   "id": "b5c76a5be9fb5baf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Get statistically relevant data from the data, such as averages, etc.\n",
    "#Using argument include='all' to analyse all columns.\n",
    "data.describe(include='all')"
   ],
   "id": "9d11596b4669cc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Using .shape to get the size of this data set\n",
    "data.shape"
   ],
   "id": "afe95b0f868f12c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Using max() to get the max value in 'sellingprice' column.\n",
    "max_value = data[\"sellingprice\"].max()\n",
    "#Using Pandas broadcasting, retrieve the row data in the dataset whose sellingprice is equal to the max_value. \n",
    "#So that we find the expensive_car in this data set.\n",
    "expensive_car = data[data[\"sellingprice\"] == max_value]\n",
    "#Show the 'make', 'model', 'seller', 'sellingprice' value\n",
    "expensive_car[[\"make\", \"model\", \"seller\", \"sellingprice\"]]"
   ],
   "id": "80eca837dd56b3e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9f47c807dae0ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T01:56:47.076834Z",
     "start_time": "2024-04-29T01:56:47.055808Z"
    }
   },
   "source": [
    "#Using Pandas broadcasting, retrieve all data in the dataset whose 'make' is equal to 'BMW' as a new data set,\n",
    "#which only contain the data of BMW cars.\n",
    "bmw = data[data[\"make\"] == \"BMW\"]\n",
    "#Using value_counts() function to calculate the times that a unique value of 'model' column in the bmw data set appeared.\n",
    "#Because the model name is unique, so the times it appeared also means how many cars of this model sold.\n",
    "bmw[\"model\"].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "3 Series                 6503\n",
       "5 Series                 3206\n",
       "X5                       1834\n",
       "7 Series                 1013\n",
       "X3                        952\n",
       "6 Series                  520\n",
       "1 Series                  321\n",
       "X1                        236\n",
       "4 Series                  217\n",
       "M3                        205\n",
       "Z4                        203\n",
       "X6                        197\n",
       "5 Series Gran Turismo     126\n",
       "M5                         80\n",
       "6 Series Gran Coupe        77\n",
       "Z3                         54\n",
       "3 Series Gran Turismo      48\n",
       "M6                         47\n",
       "2 Series                   27\n",
       "X5 M                       26\n",
       "X6 M                       18\n",
       "ActiveHybrid 7             11\n",
       "i8                          9\n",
       "4 Series Gran Coupe         9\n",
       "M4                          7\n",
       "M6 Gran Coupe               7\n",
       "ActiveHybrid X6             5\n",
       "Z4 M                        4\n",
       "ActiveHybrid 5              2\n",
       "X4                          2\n",
       "8 Series                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "2a661925a7a2961d",
   "metadata": {},
   "source": [
    "#Using Pandas broadcasting, retrieve all data in the dataset whose 'year' is equal to 2000 as a new data set,\n",
    "#which only contain the data of cars that sold in 2000.\n",
    "car_in_2000 = data[data[\"year\"] == 2000]\n",
    "#Using .shape[0] to retrieve the number of rows of the data set,\n",
    "#which is also the number of total cars sold in 2000\n",
    "car_in_2000.shape[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T01:58:03.390113Z",
     "start_time": "2024-04-29T01:58:03.371171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Using the groupby() function to organize the dataset based on the \"body\" column. \n",
    "#The [\"body\"] argument restricts the grouping to the \"body\" column exclusively\n",
    "#Using value_counts() function to quantify the occurrences of each unique body type, revealing the number of vehicles sold for each body style. \n",
    "#Next, use the sort_values() function to arrange the resulting data in descending order based on the \"counts\" column, \n",
    "#ensuring that the body types with the highest sales volumes are prioritized. \n",
    "#Finally, use head(1) function to extract the body type associated with the maximum sales quantity.\n",
    "data.groupby(\"body\")[\"body\"].value_counts().sort_values(ascending=False).head(1)"
   ],
   "id": "9514f3946dec9316",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body\n",
       "Sedan    156295\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T02:14:37.596762Z",
     "start_time": "2024-04-29T02:14:37.576727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Do the same thing as the above cell, but change the column from 'body' to 'transmission'\n",
    "data.groupby(\"transmission\")[\"transmission\"].value_counts().sort_values(ascending=False).head(1)"
   ],
   "id": "eff7d3b6b598c6ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transmission\n",
       "automatic    410026\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T02:22:27.200664Z",
     "start_time": "2024-04-29T02:22:25.867431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "different_years=data.groupby(\"year\")[[\"make\",\"model\"]].value_counts()\n",
    "different_years[\"count\"]"
   ],
   "id": "e18f07180994312a",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'count'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3790\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3791\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3792\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:152\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:160\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001B[0m, in \u001B[0;36mpandas._libs.index.Int64Engine._check_type\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m different_years\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myear\u001B[39m\u001B[38;5;124m\"\u001B[39m)[[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmake\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\u001B[38;5;241m.\u001B[39mvalue_counts()\n\u001B[1;32m----> 2\u001B[0m different_years[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcount\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\series.py:1040\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1037\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[1;32m-> 1040\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_value(key)\n\u001B[0;32m   1042\u001B[0m \u001B[38;5;66;03m# Convert generator to list before going through hashable part\u001B[39;00m\n\u001B[0;32m   1043\u001B[0m \u001B[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001B[39;00m\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\series.py:1156\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1153\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[0;32m   1155\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[1;32m-> 1156\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_loc(label)\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(loc):\n\u001B[0;32m   1159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[loc]\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2925\u001B[0m, in \u001B[0;36mMultiIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2922\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m mask\n\u001B[0;32m   2924\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m-> 2925\u001B[0m     loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_level_indexer(key, level\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m   2926\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _maybe_to_slice(loc)\n\u001B[0;32m   2928\u001B[0m keylen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(key)\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3276\u001B[0m, in \u001B[0;36mMultiIndex._get_level_indexer\u001B[1;34m(self, key, level, indexer)\u001B[0m\n\u001B[0;32m   3273\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mslice\u001B[39m(i, j, step)\n\u001B[0;32m   3275\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3276\u001B[0m     idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_loc_single_level_index(level_index, key)\n\u001B[0;32m   3278\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m level \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lexsort_depth \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   3279\u001B[0m         \u001B[38;5;66;03m# Desired level is not sorted\u001B[39;00m\n\u001B[0;32m   3280\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mslice\u001B[39m):\n\u001B[0;32m   3281\u001B[0m             \u001B[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2865\u001B[0m, in \u001B[0;36mMultiIndex._get_loc_single_level_index\u001B[1;34m(self, level_index, key)\u001B[0m\n\u001B[0;32m   2863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   2864\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2865\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m level_index\u001B[38;5;241m.\u001B[39mget_loc(key)\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3793\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3794\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3795\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3796\u001B[0m     ):\n\u001B[0;32m   3797\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3798\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3799\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3800\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3801\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3802\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'count'"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "df261f111efab4eb",
   "metadata": {},
   "source": [
    "after_2000 = data[data[\"year\"] > 2000]\n",
    "years = (after_2000.groupby(\"year\")[\"year\"].value_counts()).index\n",
    "count = (after_2000.groupby(\"year\")[\"year\"].value_counts()).values\n",
    "%matplotlib notebook\n",
    "plt.plot(years, count)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ab22e0b0148726cc",
   "metadata": {},
   "source": [
    "top10_sellers = ((data[\"seller\"].value_counts()).head(10)).index\n",
    "total_prices=[]\n",
    "for seller in top10_sellers:\n",
    "    selling_data=data[data[\"seller\"] == seller]\n",
    "    total_prices.append(selling_data[\"sellingprice\"].sum())\n",
    "\n",
    "for seller,price in zip(top10_sellers,total_prices):\n",
    "    print(seller,\"\\t\\t:\", price)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bcd9ed7d080b879d",
   "metadata": {},
   "source": [
    "plt.bar(top10_sellers,total_prices)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c886f605b29ff97",
   "metadata": {},
   "source": [
    "data.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a30c1adb7c70fd75",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
